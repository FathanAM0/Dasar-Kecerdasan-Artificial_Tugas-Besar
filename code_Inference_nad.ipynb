{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce46242",
   "metadata": {},
   "source": [
    "Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b421c1b",
   "metadata": {},
   "source": [
    "Konstanta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbeb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 48000\n",
    "SEGMENT_DURATION = int(1 * SAMPLE_RATE)\n",
    "OVERLAP_DURATION = int(0.5 * SAMPLE_RATE)\n",
    "\n",
    "MAIN_PATH = r\"C:\\Users\\Lulay\\Documents\\GitHub\\Dasar-Kecerdasan-Artificial_Tugas-Besar\"\n",
    "# MAIN_PATH = r\"D:\\Kuliah\\Matkul\\Semester 4\\DASAR KECERDASAN ARTIFICIAL (DKA)\\[2] Tugas\\[3] Tugas Besar\\Dasar-Kecerdasan-Artificial_Tugas-Besar\"\n",
    "\n",
    "dir_data_nad = MAIN_PATH+ r\"\\Dataset\\noise-audio-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b268c2",
   "metadata": {},
   "source": [
    "# Pra-Pemrosesan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c58488",
   "metadata": {},
   "source": [
    "Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811afd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_audio(path: str) -> Tuple[np.ndarray, int]:\n",
    "    audio, sr = librosa.load(path, sr=SAMPLE_RATE, mono=False)\n",
    "    return audio, sr\n",
    "\n",
    "def prapemrosesan_downmixing(audio: np.ndarray) -> np.ndarray:\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=0)\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "def prapemrosesan_resampling(audio: np.ndarray, sr: int) -> Tuple[np.ndarray, int]:\n",
    "    if sr == SAMPLE_RATE:\n",
    "        return audio.copy(), SAMPLE_RATE\n",
    "    audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "    return audio_resampled, SAMPLE_RATE\n",
    "\n",
    "def prapemrosesan_padding(audio: np.ndarray) -> np.ndarray:\n",
    "    if len(audio) % SEGMENT_DURATION != 0:\n",
    "        padding = SEGMENT_DURATION - (len(audio) % SEGMENT_DURATION)\n",
    "        audio = np.pad(audio, (0, padding), mode='constant')\n",
    "    return audio\n",
    "\n",
    "def prapemrosesan_splitting(audio: np.ndarray) -> np.ndarray:\n",
    "    num_segments = int(np.floor((len(audio) - SEGMENT_DURATION) / OVERLAP_DURATION)) + 1\n",
    "    segments = np.lib.stride_tricks.as_strided(\n",
    "        audio,\n",
    "        shape=(num_segments, SEGMENT_DURATION),\n",
    "        strides=(OVERLAP_DURATION * audio.strides[0], audio.strides[0]),\n",
    "        writeable=False\n",
    "    )\n",
    "    if len(segments[-1]) < SEGMENT_DURATION:\n",
    "        segments[-1] = np.pad(segments[-1], (0, SEGMENT_DURATION - len(segments[-1])), 'constant')\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5c662",
   "metadata": {},
   "source": [
    "Function Utama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3997883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prapemrosesan(path : str) -> np.ndarray:\n",
    "    audio, sr = load_file_audio(path)\n",
    "    audio = prapemrosesan_downmixing(audio)\n",
    "    audio, sr = prapemrosesan_resampling(audio, sr)\n",
    "    audio = prapemrosesan_padding(audio)\n",
    "    segments = prapemrosesan_splitting(audio)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798c5d5",
   "metadata": {},
   "source": [
    "# Ekstraksi Fitur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197172ae",
   "metadata": {},
   "source": [
    "Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms(segment):\n",
    "    return np.mean(librosa.feature.rms(y=segment))\n",
    "\n",
    "def get_zcr(segment):\n",
    "    return np.mean(librosa.feature.zero_crossing_rate(y=segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6c5eb",
   "metadata": {},
   "source": [
    "# Fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202937e",
   "metadata": {},
   "source": [
    "Load Scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = joblib.load(f\"{MAIN_PATH}/Model/p_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe6199",
   "metadata": {},
   "source": [
    "Squeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(rms, zcr):\n",
    "    arr = np.array([[rms, zcr]])\n",
    "    rms_zcr_scaled = scl.transform(arr)[0]\n",
    "    return rms_zcr_scaled[0], rms_zcr_scaled[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16064303",
   "metadata": {},
   "source": [
    "# Visualize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16569169",
   "metadata": {},
   "source": [
    "Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc904f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot(path, list_result, final_time):\n",
    "    file_name = os.path.basename(path)\n",
    "    audio, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    time_axis = np.linspace(0, len(audio) / sr, len(audio))\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.plot(time_axis, audio, label=\"Amplitude\")\n",
    "    plt.title(f\"Audio waveform with loud segments marked - {file_name}\") \n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "\n",
    "    for i in enumerate(list_result):\n",
    "        start_time = i[1][0]\n",
    "        end_time = i[1][1]\n",
    "        plt.axvspan(start_time, end_time, color='red', alpha=0.3)\n",
    "\n",
    "    plt.xticks(np.arange(0, final_time, 0.5))\n",
    "    plt.grid(which='both', alpha=0.5)\n",
    "    plt.xlim(0, final_time)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb8908",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d648c",
   "metadata": {},
   "source": [
    "Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(f\"{MAIN_PATH}/Model/p_lgbm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff53f75",
   "metadata": {},
   "source": [
    "# Main Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(path):\n",
    "    result = []\n",
    "\n",
    "    segments = prapemrosesan(path)\n",
    "    for i, segment in enumerate(segments):\n",
    "        start_time = round(i * 0.5, 2)\n",
    "        end_time = round(start_time + 1.0, 2)\n",
    "        timestamp = [start_time, end_time]\n",
    "\n",
    "        rms = get_rms(segment)\n",
    "        zcr = get_zcr(segment)\n",
    "        rms, zcr = normalisasi(rms, zcr)\n",
    "        label = model.predict([[rms, zcr]])[0]\n",
    "\n",
    "        result.append({\n",
    "            \"name\": path.split(\"/\")[-1],\n",
    "            \"timestamp\": timestamp,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2788c6",
   "metadata": {},
   "source": [
    "Contoh 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e910137",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_1 = r\"C:\\Users\\Lulay\\Documents\\GitHub\\Dasar-Kecerdasan-Artificial_Tugas-Besar\\Dataset\\noise-audio-data\\1-137-A-32.wav\"\n",
    "result_1 = main_pipeline(audio_1)\n",
    "\n",
    "list_label_1 = [data[\"timestamp\"] for data in result_1 if data[\"label\"] == 1]\n",
    "list_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_plot(audio_1, list_label_1, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd4952",
   "metadata": {},
   "source": [
    "Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\"{MAIN_PATH}/Dataset/noise-audio-data\"\n",
    "# folder = f\"{MAIN_PATH}/Dataset/noise-audio-data\"\n",
    "for file in os.listdir(folder):\n",
    "    path = f\"{folder}/{file}\"\n",
    "    result = main_pipeline(path)\n",
    "    list_label = [data[\"timestamp\"] for data in result if data[\"label\"] == 1]\n",
    "    print(f\"{file}, {list_label}\")\n",
    "    load_and_plot(path, list_label, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
