{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b602aa",
   "metadata": {},
   "source": [
    "Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee753d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import scipy.fftpack\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.signal import resample_poly\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c9105",
   "metadata": {},
   "source": [
    "Main Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN_PATH = r\"C:\\Users\\Lulay\\Documents\\GitHub\\Dasar-Kecerdasan-Artificial_Tugas-Besar\\Dataset\"\n",
    "MAIN_PATH = r\"D:\\Kuliah\\Matkul\\Semester 4\\DASAR KECERDASAN ARTIFICIAL (DKA)\\[2] Tugas\\[3] Tugas Besar\\Dasar-Kecerdasan-Artificial_Tugas-Besar\\Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cb01d",
   "metadata": {},
   "source": [
    "Konstanta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb566601",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 48000\n",
    "BATCH_SIZE = 32\n",
    "SEGMENT_DURATION = int(1 * SAMPLE_RATE)\n",
    "OVERLAP_DURATION = int(0.5 * SAMPLE_RATE)\n",
    "RANDOM_STATE = 21\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3f0cb",
   "metadata": {},
   "source": [
    "Random Seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23830ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 21\n",
    "\n",
    "try:\n",
    "    from sklearn.utils import check_random_state\n",
    "    random_state = check_random_state(RANDOM_SEED)\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ea7d2",
   "metadata": {},
   "source": [
    "# Prapemrosesan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7645f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_audio(path):\n",
    "    audio, sr = sf.read(path)\n",
    "    return np.array(audio), sr\n",
    "\n",
    "def prapemrosesan_downmixing(audio):\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "def prapemrosesan_resampling(audio, sr):\n",
    "    if sr == SAMPLE_RATE:\n",
    "        return audio.copy(), SAMPLE_RATE\n",
    "    \n",
    "    ratio = SAMPLE_RATE / sr\n",
    "    n_samples = int(np.round(len(audio) * ratio))\n",
    "    \n",
    "    x_old = np.linspace(0, 1, len(audio))\n",
    "    x_new = np.linspace(0, 1, n_samples)\n",
    "    return np.interp(x_new, x_old, audio), SAMPLE_RATE\n",
    "\n",
    "def prapemrosesan_padding(audio):\n",
    "    if np.mod(audio.shape[0], SEGMENT_DURATION) != 0:\n",
    "        padding = SEGMENT_DURATION - (audio.shape[0] % SEGMENT_DURATION)\n",
    "        audio = np.pad(audio, (0, padding))\n",
    "    return audio\n",
    "\n",
    "def prapemrosesan_splitting(audio):\n",
    "    num_segments = int(np.floor((len(audio) - SEGMENT_DURATION) / OVERLAP_DURATION)) + 1\n",
    "    segments = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start = int(i * OVERLAP_DURATION)\n",
    "        end = int(start + SEGMENT_DURATION)\n",
    "        segment = audio[start:end]\n",
    "        if len(segment) < SEGMENT_DURATION:\n",
    "            segment = np.pad(segment, (0, SEGMENT_DURATION - len(segment)), mode='constant')\n",
    "        segments.append(segment)\n",
    "\n",
    "    return np.array(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bdc6f",
   "metadata": {},
   "source": [
    "# Ekstraksi Fitur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms(segment):\n",
    "    return np.sqrt(np.mean(segment ** 2))\n",
    "\n",
    "def get_zcr(segment):\n",
    "    return np.sum(np.abs(np.diff(np.signbit(segment)))) / (len(segment) / SAMPLE_RATE)\n",
    "\n",
    "def get_lms(segment):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=segment, sr=SAMPLE_RATE)\n",
    "    return np.mean(mel_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12e4b9",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933b090",
   "metadata": {},
   "source": [
    "Raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{MAIN_PATH}/dataset_preprocessed.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b79783",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bc65",
   "metadata": {},
   "source": [
    "Normalisasi, Split, dan Batching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23123425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[data[3], data[4]] for data in dataset if data[2] != 2]\n",
    "y = [int(data[2]) for data in dataset if data[2] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_STATE, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "X_train_scaled = scl.fit_transform(X_train)\n",
    "X_test_scaled = scl.transform(X_test)\n",
    "X_val_scaled = scl.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    X_train_scaled.shape,\n",
    "    X_test_scaled.shape,\n",
    "    X_val_scaled.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489cdf8",
   "metadata": {},
   "source": [
    "# LGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819e38b",
   "metadata": {},
   "source": [
    "Inisialisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(random_state=RANDOM_STATE, verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d850c73",
   "metadata": {},
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e996b4",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab12b34",
   "metadata": {},
   "source": [
    "Inisialisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf57b7",
   "metadata": {},
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f039d",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65ad71",
   "metadata": {},
   "source": [
    "Inisialisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61777c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super(CNN, self).__init__()\n",
    "#         test_input = np.random.rand(SAMPLE_RATE * SEGMENT_DURATION)\n",
    "#         lms = get_lms(test_input)\n",
    "#         in_channels = 1\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(128)\n",
    "#         self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(256)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc1 = nn.Linear(256, 256)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.fc2 = nn.Linear(256, num_classes)\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "#         x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "#         x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "#         x = self.gap(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa897f2a",
   "metadata": {},
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9952b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1acea605",
   "metadata": {},
   "source": [
    "# Conformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831016da",
   "metadata": {},
   "source": [
    "Inisialisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ebf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = ConformerConfig(\n",
    "#     hidden_size=144,\n",
    "#     num_attention_heads=4,\n",
    "#     intermediate_size=576,\n",
    "#     conv_kernel_size=32,\n",
    "#     num_hidden_layers=8,\n",
    "#     input_feat_per_channel=n_mels,\n",
    "#     input_channels=1,\n",
    "#     max_position_embeddings=time_steps\n",
    "# )\n",
    "\n",
    "# conformer_model = TFConformerModel(config)\n",
    "\n",
    "# input_layer = tf.keras.layers.Input(shape=(n_mels, time_steps))\n",
    "# expand_dim = tf.keras.layers.Reshape((1, n_mels, time_steps))(input_layer)\n",
    "# conv_proj = tf.keras.layers.Conv2D(\n",
    "#     filters=config.hidden_size,\n",
    "#     kernel_size=(3, 3),\n",
    "#     padding='same',\n",
    "#     activation='relu'\n",
    "# )(expand_dim)\n",
    "# squeeze_dim = tf.keras.layers.Reshape((n_mels, time_steps, config.hidden_size))(conv_proj)\n",
    "# conformer_output = conformer_model(squeeze_dim).last_hidden_state\n",
    "# gap = tf.keras.layers.GlobalAveragePooling1D()(conformer_output)\n",
    "# output = tf.keras.layers.Dense(num_classes, activation='softmax')(gap)\n",
    "\n",
    "# conformer_model = tf.keras.Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97caca83",
   "metadata": {},
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f76e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27746d29",
   "metadata": {},
   "source": [
    "# Model Lain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cff1a",
   "metadata": {},
   "source": [
    "inisialisasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd55db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"rf\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"xg\": XGBClassifier(random_state=RANDOM_STATE),\n",
    "    \"cat\": CatBoostClassifier(random_state=RANDOM_STATE, verbose=0),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"lr\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"dt\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"svm\": SVC(random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6bbfad",
   "metadata": {},
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9accd5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_input, y_train)\n",
    "    y_pred = model.predict(X_test_input)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31168e6c",
   "metadata": {},
   "source": [
    "# Evaluasi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0bb020",
   "metadata": {},
   "source": [
    "LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_model.predict(X_val_scaled)\n",
    "\n",
    "print(\"Validasi\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_val, y_pred)}\")\n",
    "\n",
    "y_pred = lgbm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Test\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e7fcc",
   "metadata": {},
   "source": [
    "CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9c438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4c31",
   "metadata": {},
   "source": [
    "Conformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0ff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7506e4",
   "metadata": {},
   "source": [
    "Descision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade969c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_model.predict(X_val_scaled)\n",
    "\n",
    "print(\"Validasi\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_val, y_pred)}\")\n",
    "\n",
    "y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Test\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['RMS', 'ZCR']\n",
    "tree_rules = export_text(dt_model, feature_names=feature_names)\n",
    "print(\"Extracted Decision Rules:\")\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb0b46",
   "metadata": {},
   "source": [
    "Model Lain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"{model_name} Model:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8b805",
   "metadata": {},
   "source": [
    "# Visualisasi Hasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070df803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot(path, list_result, final_time):\n",
    "    file_name = os.path.basename(path)\n",
    "    audio, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    time_axis = np.linspace(0, len(audio) / sr, len(audio))\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.plot(time_axis, audio, label=\"Amplitude\")\n",
    "    plt.title(f\"Audio waveform with loud segments marked - {file_name}\") \n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "\n",
    "    for i in enumerate(list_result):\n",
    "        start_time = i[1][0]\n",
    "        end_time = i[1][1]\n",
    "        plt.axvspan(start_time, end_time, color='red', alpha=0.3)\n",
    "\n",
    "    plt.xticks(np.arange(0, final_time, 0.5))\n",
    "    plt.grid(which='both', alpha=0.5)\n",
    "    plt.xlim(0, final_time)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dacb3",
   "metadata": {},
   "source": [
    "### LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_inference(path):\n",
    "    audio, sr = load_file_audio(path)\n",
    "    audio = prapemrosesan_downmixing(audio)\n",
    "    audio, sr = prapemrosesan_resampling(audio, sr)\n",
    "    audio = prapemrosesan_padding(audio)\n",
    "    segments = prapemrosesan_splitting(audio)\n",
    "    \n",
    "    list_result = []\n",
    "    for index, segment in enumerate(segments):\n",
    "        rms = get_rms(segment)\n",
    "        zcr = get_zcr(segment)\n",
    "        X = np.array([rms, zcr])\n",
    "        X = scl.transform(X.reshape(1, -1))\n",
    "\n",
    "        y_pred = lgbm_model.predict(X)\n",
    "        if y_pred == 0:\n",
    "            list_result.append(([index*0.5, index*0.5 + 1]))\n",
    "    return list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ed854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(f\"{MAIN_PATH}/noise-audio-data\"):\n",
    "#     list_result = single_inference(f\"{MAIN_PATH}/noise-audio-data/{file}\")\n",
    "#     print(list_result)\n",
    "#     load_and_plot(f\"{MAIN_PATH}/noise-audio-data/{file}\", list_result, 5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(f\"{MAIN_PATH}/xeno-canto\"):\n",
    "#     list_result = single_inference(f\"{MAIN_PATH}/xeno-canto/{file}\")\n",
    "#     print(list_result)\n",
    "#     load_and_plot(f\"{MAIN_PATH}/xeno-canto/{file}\", list_result, 25)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
